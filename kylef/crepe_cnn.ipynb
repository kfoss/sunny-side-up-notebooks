{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git status -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape, Flatten, Merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, Convolution1D, MaxPooling2D, MaxPooling1D\n",
    "from keras.datasets import imdb, reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_path(fullpath):\n",
    "    \"\"\" \n",
    "    Import a file with full path specification. Allows one to\n",
    "    import from anywhere, something __import__ does not do. \n",
    "    \"\"\"\n",
    "    import os, sys\n",
    "    path, filename = os.path.split(fullpath)\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    sys.path.append(path)\n",
    "    module = __import__(filename)\n",
    "    reload(module) # Might be out of date\n",
    "    del sys.path[-1]\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imdb_load = import_path('/data/imports/imdb_load.py')\n",
    "imdb_load = import_path('/data/notebooks/imports/imdb_load_dataframe.py')\n",
    "load_character_encoded_data = imdb_load.load_character_encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Train a CNN on the IMDB sentiment classification task.\n",
    "\n",
    "    GPU command:\n",
    "        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "nb_epoch = 10\n",
    "max_features = 20000\n",
    "maxlen = 1014 # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 128\n",
    "nb_classes = 1\n",
    "nb_feature_maps = 32\n",
    "embedding_size = 67\n",
    "fully_connected_size = 512 \n",
    "filter_size_row = 1\n",
    "filter_size_col = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "(X_train, Y_train), (X_test, Y_test) = load_character_encoded_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/pickles/imdb_x_train.pkl', 'wb') as p:\n",
    "  pickle.dump(X_train, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/pickles/imdb_x_test.pkl', 'wb') as p:\n",
    "  pickle.dump(X_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/pickles/imdb_y_train.pkl', 'wb') as p:\n",
    "  pickle.dump(Y_train, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/pickles/imdb_y_test.pkl', 'wb') as p:\n",
    "  pickle.dump(Y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/pickles/imdb_x_train.pkl', 'rb') as p:\n",
    "  X_train = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_4d = X_train.reshape(X_train.shape[0], 1, 1014, embedding_size)\n",
    "X_test_4d = X_test.reshape(X_test.shape[0], 1, 1014, embedding_size)\n",
    "X_train_4d = X_train_4d.astype(\"float32\")\n",
    "X_test_4d = X_test_4d.astype(\"float32\")\n",
    "print(X_train_4d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('Build model...')\n",
    "#\n",
    "## initialize the neural net and reshape the data\n",
    "#model = Sequential()\n",
    "#\n",
    "#model.add(Convolution2D(32, 1, 3, 3, border_mode='full'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(32, 32, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(poolsize=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(8*1*1014*70, 128))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#\n",
    "#model.add(Dense(128, nb_classes))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fully_connected = [8704,1024,1024,1]\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "print(\"Going into first layer\")\n",
    "model.add(Convolution1D(embedding_size,256,7))\n",
    "model.add(MaxPooling1D(pool_length=3))\n",
    "\n",
    "print(\"Going into second layer\")\n",
    "model.add(Convolution1D(256,256,7))\n",
    "model.add(MaxPooling1D(pool_length=3))\n",
    "\n",
    "print(\"Going into third layer\")\n",
    "model.add(Convolution1D(256,256,3))\n",
    "\n",
    "print(\"Going into fourth layer\")\n",
    "model.add(Convolution1D(256,256,3))\n",
    "\n",
    "print(\"Going into fifth layer\")\n",
    "model.add(Convolution1D(256,256,3))\n",
    "\n",
    "print(\"Going into sixth layer\")\n",
    "model.add(Convolution1D(256,256,3))\n",
    "model.add(MaxPooling1D(pool_length=3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "print(\"Going into fully Connected layer\")\n",
    "#Fully Connected Layers \n",
    "model.add(Dense(fully_connected[0], fully_connected[1]))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(fully_connected[1], fully_connected[2]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(fully_connected[2], fully_connected[3]))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( \"Training proportion of positive tweets: {}%\".format(100*Y_train.sum()/len(Y_train)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train...\")\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Score...\")\n",
    "score, acc = model.evaluate(X_test, Y_test, batch_size=batch_size, show_accuracy=True)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the neural net and reshape the data\n",
    "model = Sequential()\n",
    "#model.add(Embedding(max_features, embedding_size)) # embed into dense 3D float tensor (samples, maxlen, 256)\n",
    "#model.add(Reshape(1, maxlen, embedding_size)) # reshape into 4D tensor (samples, 1, maxlen, 256)\n",
    "\n",
    "# convolution stack\n",
    "model.add(Convolution2D(nb_feature_maps, nb_classes, filter_size_row, filter_size_col, border_mode='full')) # reshaped to 32 x maxlen x 256 (32 x 100 x 256)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# convolution stack with regularization\n",
    "model.add(Convolution2D(nb_feature_maps, nb_feature_maps, filter_size_row, filter_size_col, border_mode='full')) # reshaped to 32 x maxlen x 256 (32 x 100 x 256)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2))) # reshaped to 32 x maxlen/2 x 256/2 (32 x 50 x 128)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# convolution stack with regularization\n",
    "model.add(Convolution2D(nb_feature_maps, nb_feature_maps, filter_size_row, filter_size_col)) # reshaped to 32 x 50 x 128\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2, 2))) # reshaped to 32 x maxlen/2/2 x 256/2/2 (32 x 25 x 64)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# fully-connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_feature_maps * (maxlen/2/2) * (embedding_size/2/2), fully_connected_size))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "# output classifier\n",
    "model.add(Dense(fully_connected_size, nb_classes))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_4d, Y_train, batch_size=32, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test_4d, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Score...\")\n",
    "score, acc = model.evaluate(X_test_4d, Y_test, batch_size=batch_size, show_accuracy=True)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}